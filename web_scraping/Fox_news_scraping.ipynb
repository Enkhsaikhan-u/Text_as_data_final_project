{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9905ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfa691af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1: https://www.foxnews.com/category/us/economy?page=1\n",
      "Scraping Page 2: https://www.foxnews.com/category/us/economy?page=2\n",
      "Scraping Page 3: https://www.foxnews.com/category/us/economy?page=3\n",
      "Scraping Page 4: https://www.foxnews.com/category/us/economy?page=4\n",
      "Scraping Page 5: https://www.foxnews.com/category/us/economy?page=5\n",
      "Scraping Page 6: https://www.foxnews.com/category/us/economy?page=6\n",
      "Scraping Page 7: https://www.foxnews.com/category/us/economy?page=7\n",
      "Scraping Page 8: https://www.foxnews.com/category/us/economy?page=8\n",
      "Scraping Page 9: https://www.foxnews.com/category/us/economy?page=9\n",
      "Scraping Page 10: https://www.foxnews.com/category/us/economy?page=10\n",
      "Scraping Page 11: https://www.foxnews.com/category/us/economy?page=11\n",
      "Scraping Page 12: https://www.foxnews.com/category/us/economy?page=12\n",
      "Scraping Page 13: https://www.foxnews.com/category/us/economy?page=13\n",
      "Scraping Page 14: https://www.foxnews.com/category/us/economy?page=14\n",
      "Scraping Page 15: https://www.foxnews.com/category/us/economy?page=15\n",
      "Scraping Page 16: https://www.foxnews.com/category/us/economy?page=16\n",
      "Scraping Page 17: https://www.foxnews.com/category/us/economy?page=17\n",
      "Scraping Page 18: https://www.foxnews.com/category/us/economy?page=18\n",
      "Scraping Page 19: https://www.foxnews.com/category/us/economy?page=19\n",
      "Scraping Page 20: https://www.foxnews.com/category/us/economy?page=20\n",
      "Scraping Page 21: https://www.foxnews.com/category/us/economy?page=21\n",
      "Scraping Page 22: https://www.foxnews.com/category/us/economy?page=22\n",
      "Scraping Page 23: https://www.foxnews.com/category/us/economy?page=23\n",
      "Scraping Page 24: https://www.foxnews.com/category/us/economy?page=24\n",
      "Scraping Page 25: https://www.foxnews.com/category/us/economy?page=25\n",
      "Scraping Page 26: https://www.foxnews.com/category/us/economy?page=26\n",
      "Scraping Page 27: https://www.foxnews.com/category/us/economy?page=27\n",
      "Scraping Page 28: https://www.foxnews.com/category/us/economy?page=28\n",
      "Scraping Page 29: https://www.foxnews.com/category/us/economy?page=29\n",
      "Scraping Page 30: https://www.foxnews.com/category/us/economy?page=30\n",
      "Scraping Page 31: https://www.foxnews.com/category/us/economy?page=31\n",
      "Scraping Page 32: https://www.foxnews.com/category/us/economy?page=32\n",
      "Scraping Page 33: https://www.foxnews.com/category/us/economy?page=33\n",
      "Scraping Page 34: https://www.foxnews.com/category/us/economy?page=34\n",
      "Scraping Page 35: https://www.foxnews.com/category/us/economy?page=35\n",
      "Scraping Page 36: https://www.foxnews.com/category/us/economy?page=36\n",
      "Scraping Page 37: https://www.foxnews.com/category/us/economy?page=37\n",
      "Scraping Page 38: https://www.foxnews.com/category/us/economy?page=38\n",
      "Scraping Page 39: https://www.foxnews.com/category/us/economy?page=39\n",
      "Scraping Page 40: https://www.foxnews.com/category/us/economy?page=40\n",
      "Scraping Page 41: https://www.foxnews.com/category/us/economy?page=41\n",
      "Scraping Page 42: https://www.foxnews.com/category/us/economy?page=42\n",
      "Scraping Page 43: https://www.foxnews.com/category/us/economy?page=43\n",
      "Scraping Page 44: https://www.foxnews.com/category/us/economy?page=44\n",
      "Scraping Page 45: https://www.foxnews.com/category/us/economy?page=45\n",
      "Scraping Page 46: https://www.foxnews.com/category/us/economy?page=46\n",
      "Scraping Page 47: https://www.foxnews.com/category/us/economy?page=47\n",
      "Scraping Page 48: https://www.foxnews.com/category/us/economy?page=48\n",
      "Scraping Page 49: https://www.foxnews.com/category/us/economy?page=49\n",
      "Scraping Page 50: https://www.foxnews.com/category/us/economy?page=50\n",
      "No new links found on page 50 (1/5)\n",
      "Scraping Page 51: https://www.foxnews.com/category/us/economy?page=51\n",
      "Scraping Page 52: https://www.foxnews.com/category/us/economy?page=52\n",
      "Scraping Page 53: https://www.foxnews.com/category/us/economy?page=53\n",
      "Scraping Page 54: https://www.foxnews.com/category/us/economy?page=54\n",
      "Scraping Page 55: https://www.foxnews.com/category/us/economy?page=55\n",
      "Scraping Page 56: https://www.foxnews.com/category/us/economy?page=56\n",
      "Scraping Page 57: https://www.foxnews.com/category/us/economy?page=57\n",
      "Scraping Page 58: https://www.foxnews.com/category/us/economy?page=58\n",
      "Scraping Page 59: https://www.foxnews.com/category/us/economy?page=59\n",
      "Scraping Page 60: https://www.foxnews.com/category/us/economy?page=60\n",
      "Scraping Page 61: https://www.foxnews.com/category/us/economy?page=61\n",
      "Scraping Page 62: https://www.foxnews.com/category/us/economy?page=62\n",
      "Scraping Page 63: https://www.foxnews.com/category/us/economy?page=63\n",
      "Scraping Page 64: https://www.foxnews.com/category/us/economy?page=64\n",
      "Scraping Page 65: https://www.foxnews.com/category/us/economy?page=65\n",
      "Scraping Page 66: https://www.foxnews.com/category/us/economy?page=66\n",
      "Scraping Page 67: https://www.foxnews.com/category/us/economy?page=67\n",
      "Scraping Page 68: https://www.foxnews.com/category/us/economy?page=68\n",
      "Scraping Page 69: https://www.foxnews.com/category/us/economy?page=69\n",
      "Scraping Page 70: https://www.foxnews.com/category/us/economy?page=70\n",
      "Scraping Page 71: https://www.foxnews.com/category/us/economy?page=71\n",
      "Scraping Page 72: https://www.foxnews.com/category/us/economy?page=72\n",
      "Scraping Page 73: https://www.foxnews.com/category/us/economy?page=73\n",
      "Scraping Page 74: https://www.foxnews.com/category/us/economy?page=74\n",
      "Scraping Page 75: https://www.foxnews.com/category/us/economy?page=75\n",
      "Scraping Page 76: https://www.foxnews.com/category/us/economy?page=76\n",
      "Scraping Page 77: https://www.foxnews.com/category/us/economy?page=77\n",
      "Scraping Page 78: https://www.foxnews.com/category/us/economy?page=78\n",
      "Scraping Page 79: https://www.foxnews.com/category/us/economy?page=79\n",
      "Scraping Page 80: https://www.foxnews.com/category/us/economy?page=80\n",
      "Scraping Page 81: https://www.foxnews.com/category/us/economy?page=81\n",
      "Scraping Page 82: https://www.foxnews.com/category/us/economy?page=82\n",
      "Scraping Page 83: https://www.foxnews.com/category/us/economy?page=83\n",
      "Scraping Page 84: https://www.foxnews.com/category/us/economy?page=84\n",
      "Scraping Page 85: https://www.foxnews.com/category/us/economy?page=85\n",
      "Scraping Page 86: https://www.foxnews.com/category/us/economy?page=86\n",
      "Scraping Page 87: https://www.foxnews.com/category/us/economy?page=87\n",
      "Scraping Page 88: https://www.foxnews.com/category/us/economy?page=88\n",
      "Scraping Page 89: https://www.foxnews.com/category/us/economy?page=89\n",
      "Scraping Page 90: https://www.foxnews.com/category/us/economy?page=90\n",
      "Scraping Page 91: https://www.foxnews.com/category/us/economy?page=91\n",
      "Scraping Page 92: https://www.foxnews.com/category/us/economy?page=92\n",
      "Scraping Page 93: https://www.foxnews.com/category/us/economy?page=93\n",
      "Scraping Page 94: https://www.foxnews.com/category/us/economy?page=94\n",
      "Scraping Page 95: https://www.foxnews.com/category/us/economy?page=95\n",
      "Scraping Page 96: https://www.foxnews.com/category/us/economy?page=96\n",
      "Scraping Page 97: https://www.foxnews.com/category/us/economy?page=97\n",
      "Scraping Page 98: https://www.foxnews.com/category/us/economy?page=98\n",
      "Scraping Page 99: https://www.foxnews.com/category/us/economy?page=99\n",
      "Scraping Page 100: https://www.foxnews.com/category/us/economy?page=100\n",
      "Scraping Page 101: https://www.foxnews.com/category/us/economy?page=101\n",
      "Scraping Page 102: https://www.foxnews.com/category/us/economy?page=102\n",
      "Scraping Page 103: https://www.foxnews.com/category/us/economy?page=103\n",
      "Scraping Page 104: https://www.foxnews.com/category/us/economy?page=104\n",
      "Scraping Page 105: https://www.foxnews.com/category/us/economy?page=105\n",
      "Scraping Page 106: https://www.foxnews.com/category/us/economy?page=106\n",
      "Scraping Page 107: https://www.foxnews.com/category/us/economy?page=107\n",
      "Scraping Page 108: https://www.foxnews.com/category/us/economy?page=108\n",
      "Scraping Page 109: https://www.foxnews.com/category/us/economy?page=109\n",
      "Scraping Page 110: https://www.foxnews.com/category/us/economy?page=110\n",
      "Scraping Page 111: https://www.foxnews.com/category/us/economy?page=111\n",
      "Scraping Page 112: https://www.foxnews.com/category/us/economy?page=112\n",
      "Scraping Page 113: https://www.foxnews.com/category/us/economy?page=113\n",
      "Scraping Page 114: https://www.foxnews.com/category/us/economy?page=114\n",
      "Scraping Page 115: https://www.foxnews.com/category/us/economy?page=115\n",
      "Scraping Page 116: https://www.foxnews.com/category/us/economy?page=116\n",
      "Scraping Page 117: https://www.foxnews.com/category/us/economy?page=117\n",
      "Scraping Page 118: https://www.foxnews.com/category/us/economy?page=118\n",
      "Scraping Page 119: https://www.foxnews.com/category/us/economy?page=119\n",
      "Scraping Page 120: https://www.foxnews.com/category/us/economy?page=120\n",
      "Scraping Page 121: https://www.foxnews.com/category/us/economy?page=121\n",
      "Scraping Page 122: https://www.foxnews.com/category/us/economy?page=122\n",
      "Scraping Page 123: https://www.foxnews.com/category/us/economy?page=123\n",
      "Scraping Page 124: https://www.foxnews.com/category/us/economy?page=124\n",
      "Scraping Page 125: https://www.foxnews.com/category/us/economy?page=125\n",
      "Scraping Page 126: https://www.foxnews.com/category/us/economy?page=126\n",
      "Scraping Page 127: https://www.foxnews.com/category/us/economy?page=127\n",
      "Scraping Page 128: https://www.foxnews.com/category/us/economy?page=128\n",
      "Scraping Page 129: https://www.foxnews.com/category/us/economy?page=129\n",
      "----------------------------------------\n",
      "Total unique Fox News links collected: 756\n",
      "Links saved to: C:\\Users\\Enkhsaikhan\\Final_paper_text_as_data\\raw_data\\foxnews_links.csv\n",
      "                                                link\n",
      "0  https://www.foxnews.com/politics/affordability...\n",
      "1  https://www.foxnews.com/politics/perception-vs...\n",
      "2  https://www.foxnews.com/opinion/sec-turner-hom...\n",
      "3  https://www.foxnews.com/opinion/im-new-virgini...\n",
      "4  https://www.foxnews.com/tech/3d-printed-housin...\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 1. PATHS\n",
    "# ----------------------------------------------------\n",
    "\n",
    "RAW_DATA_DIR = r\"C:\\Users\\Enkhsaikhan\\Final_paper_text_as_data\\raw_data\"\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "OUTPUT_FILE = os.path.join(RAW_DATA_DIR, \"foxnews_links.csv\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. CONFIG\n",
    "# ----------------------------------------------------\n",
    "\n",
    "SEARCH_URL_PATTERN = \"https://www.foxnews.com/category/us/economy?page={}\"\n",
    "BASE_DOMAIN = \"https://www.foxnews.com\"\n",
    "MAX_PAGES_TO_TRY = 129  # increase to cover all pages\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/121.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Stop only after this many consecutive empty pages\n",
    "MAX_EMPTY_CONSECUTIVE = 5\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. SCRAPER FUNCTION\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def scrape_fox_news_page(page_num, seen_links):\n",
    "    url = SEARCH_URL_PATTERN.format(page_num)\n",
    "    print(f\"Scraping Page {page_num}: {url}\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Status code {r.status_code} — skipping page.\")\n",
    "            return []\n",
    "\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "        container = soup.find(\"div\", class_=\"content article-list\")\n",
    "        if not container:\n",
    "            print(\"No article container found — page may be empty.\")\n",
    "            return []\n",
    "\n",
    "        articles = container.find_all(\"article\", class_=\"article\")\n",
    "        new_links = []\n",
    "\n",
    "        for article in articles:\n",
    "            # Skip videos\n",
    "            eyebrow = article.find(\"span\", class_=\"eyebrow\")\n",
    "            if eyebrow and \"VIDEO\" in eyebrow.get_text(strip=True).upper():\n",
    "                continue\n",
    "\n",
    "            headline = article.find(\"h4\", class_=\"title\")\n",
    "            link_tag = headline.find(\"a\", href=True) if headline else None\n",
    "\n",
    "            if not link_tag:\n",
    "                continue\n",
    "\n",
    "            full_url = urljoin(BASE_DOMAIN, link_tag[\"href\"])\n",
    "\n",
    "            if full_url not in seen_links:\n",
    "                seen_links.add(full_url)\n",
    "                new_links.append(full_url)\n",
    "\n",
    "        return new_links\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page_num}: {e}\")\n",
    "        return []\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. MAIN LOOP\n",
    "# ----------------------------------------------------\n",
    "\n",
    "all_links = []\n",
    "seen_links = set()\n",
    "consecutive_empty = 0\n",
    "\n",
    "for page in range(1, MAX_PAGES_TO_TRY + 1):\n",
    "    page_links = scrape_fox_news_page(page, seen_links)\n",
    "\n",
    "    if not page_links:\n",
    "        consecutive_empty += 1\n",
    "        print(f\"No new links found on page {page} ({consecutive_empty}/{MAX_EMPTY_CONSECUTIVE})\")\n",
    "        if consecutive_empty >= MAX_EMPTY_CONSECUTIVE:\n",
    "            print(f\"Stopping after {MAX_EMPTY_CONSECUTIVE} consecutive empty pages.\")\n",
    "            break\n",
    "    else:\n",
    "        consecutive_empty = 0\n",
    "        all_links.extend(page_links)\n",
    "\n",
    "    time.sleep(1)  # politeness delay\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total unique Fox News links collected: {len(all_links)}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. SAVE TO CSV\n",
    "# ----------------------------------------------------\n",
    "\n",
    "df = pd.DataFrame({\"link\": all_links})\n",
    "df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Links saved to: {OUTPUT_FILE}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62201bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0729cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 756 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 756/756 [14:42<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Scraping finished: 756 articles saved.\n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/politics/affordability...   \n",
      "1  https://www.foxnews.com/politics/perception-vs...   \n",
      "2  https://www.foxnews.com/opinion/sec-turner-hom...   \n",
      "3  https://www.foxnews.com/opinion/im-new-virgini...   \n",
      "4  https://www.foxnews.com/tech/3d-printed-housin...   \n",
      "\n",
      "                                            headline  \\\n",
      "0  Affordability: The issue that boosted Trump an...   \n",
      "1  ‘Perception vs. reality’: Trump’s economy pick...   \n",
      "2  SEC TURNER: Homeownership is making a comeback...   \n",
      "3  I’m the new Virginia governor and affordabilit...   \n",
      "4  3D-printed housing project for student apartme...   \n",
      "\n",
      "                                                body        date  \n",
      "0  O'Leary Ventures chairman Kevin O'Leary analyz...  2025-12-27  \n",
      "1  Unleash Prosperity co-founder Stephen Moore sa...  2025-12-27  \n",
      "2  Citizens Alliance CEO Cliff Maloney joins 'Sat...  2025-12-26  \n",
      "3  O'Leary Ventures chairman Kevin O'Leary analyz...  2025-12-26  \n",
      "4  A few hundred robots moved a building that cov...  2025-12-24  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Prepare data for processing\n",
    "# -------------------------------\n",
    "# all_links is your existing list of Fox News URLs\n",
    "indexed_data = [{\"index\": i, \"url\": url} for i, url in enumerate(all_links)]\n",
    "\n",
    "# Copy structure for final results\n",
    "final_data = [{\"url\": url, \"headline\": None, \"body\": None, \"date\": None} for url in all_links]\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Scraper function\n",
    "# -------------------------------\n",
    "def scrape_article(article_data):\n",
    "    \"\"\"\n",
    "    Scrapes a Fox News article given its URL.\n",
    "    Returns (index, headline, body_text, date)\n",
    "    \"\"\"\n",
    "    url = article_data[\"url\"]\n",
    "    idx = article_data[\"index\"]\n",
    "    article_text = None\n",
    "    article_date = None\n",
    "    article_headline = None\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return idx, None, None, None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # --- Headline ---\n",
    "        headline_tag = soup.find(\"h1\", class_=\"headline speakable\")\n",
    "        if headline_tag:\n",
    "            article_headline = headline_tag.get_text(strip=True)\n",
    "\n",
    "        # --- Article body ---\n",
    "        article_div = soup.find(\"div\", class_=\"article-body\")\n",
    "        if not article_div:\n",
    "            article_div = soup.find(\"div\", class_=\"article-content\")\n",
    "        if not article_div:\n",
    "            article_div = soup.find(\"div\", class_=\"page-content\")\n",
    "\n",
    "        if article_div:\n",
    "            paragraphs = article_div.find_all(\"p\")\n",
    "            article_text = \"\\n\".join(\n",
    "                p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)\n",
    "            )\n",
    "\n",
    "        # --- Article date ---\n",
    "        time_tag = soup.find(\"time\")\n",
    "        if time_tag and time_tag.has_attr(\"datetime\"):\n",
    "            article_date = time_tag[\"datetime\"].split(\"T\")[0]\n",
    "\n",
    "        return idx, article_headline, article_text, article_date\n",
    "\n",
    "    except Exception:\n",
    "        return idx, None, None, None\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Run scraper in parallel\n",
    "# -------------------------------\n",
    "print(f\"Scraping {len(indexed_data)} articles...\")\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:  # keep 1 to avoid rate-limiting\n",
    "    futures = [executor.submit(scrape_article, item) for item in indexed_data]\n",
    "\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(indexed_data)):\n",
    "        idx, headline, text, date = future.result()\n",
    "        final_data[idx][\"headline\"] = headline\n",
    "        final_data[idx][\"body\"] = text\n",
    "        final_data[idx][\"date\"] = date\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Save results to CSV\n",
    "# -------------------------------\n",
    "RAW_DATA_DIR = r\"C:\\Users\\Enkhsaikhan\\Final_paper_text_as_data\\raw_data\"\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "OUTPUT_FILE = os.path.join(RAW_DATA_DIR, \"foxnews_articles.csv\")\n",
    "\n",
    "df_articles = pd.DataFrame(final_data)\n",
    "df_articles.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Scraping finished: {len(df_articles)} articles saved.\")\n",
    "print(df_articles.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
